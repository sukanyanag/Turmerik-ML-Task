{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib4WW_w1g8EH",
        "outputId": "8a4a0f5f-88cb-4927-fa82-45d3606a109f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/191.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m174.1/191.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install praw transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Uxg0Kc85g4Lm"
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "from praw.models import MoreComments\n",
        "import pandas as pd\n",
        "import time\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping"
      ],
      "metadata": {
        "id": "1XNfmKA60Mxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5d9aZRwhiIiz"
      },
      "outputs": [],
      "source": [
        "# Setup PRAW with Reddit API credentials\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"EHSVoqAsOGZNHtnry4ACoQ\",\n",
        "    client_secret=\"D_iEQYt3Jhq_pszBiTK8ju6GeJht4Q\",\n",
        "    password=\"gyhxa8-qeqqom-Nawfuj\",\n",
        "    user_agent=\"Turmerik Task by u/browniekanya\",\n",
        "    username=\"browniekanya\",\n",
        "    check_for_async=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X_l02kZRVEjI"
      },
      "outputs": [],
      "source": [
        "# List of subreddits to scrape\n",
        "subreddits = [\n",
        "    \"health\", \"AskDocs\", \"medical\", \"clinicalresearch\", \"medicine\",\n",
        "    \"cancer\", \"diabetes\", \"MultipleSclerosis\", \"Epilepsy\",\n",
        "    \"ChronicPain\", \"IBD\", \"CrohnsDisease\", \"UlcerativeColitis\",\n",
        "    \"Psoriasis\", \"eczema\", \"Allergies\", \"Asthma\", \"lupus\", \"mentalhealth\",\n",
        "    \"depression\", \"BipolarReddit\", \"schizophrenia\", \"Anxiety\", \"ADHD\", \"autism\",\n",
        "    \"addiction\", \"stopsmoking\", \"OpiatesRecovery\", \"alcoholism\", \"stopdrinking\",\n",
        "    \"WeightLossAdvice\", \"loseit\", \"fitness\", \"HealthyFood\", \"nutrition\",\n",
        "    \"Supplements\", \"intermittentfasting\", \"keto\", \"vegan\", \"vegetarian\",\n",
        "    \"GERD\", \"stroke\", \"hypertension\", \"Dermatology\", \"SkincareAddiction\",\n",
        "    \"WomensHealth\", \"menshealth\", \"healthcare\", \"publichealth\", \"globalhealth\",\n",
        "    \"healthIT\", \"TeleMedicine\", \"HealthInsurance\", \"epidemiology\",\n",
        "    \"biology\", \"genetics\", \"Vitiligo\", \"Oncology\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oSXGBB--XOsK"
      },
      "outputs": [],
      "source": [
        "# Function to scrape data\n",
        "def scrape_subreddits(subreddit_list, limit_per_subreddit=50, search_term=\"clinical trial\"):\n",
        "    all_posts = []\n",
        "    for subreddit in subreddit_list:\n",
        "        sub = reddit.subreddit(subreddit)\n",
        "        for post in sub.hot(limit=limit_per_subreddit):\n",
        "            post_dict = {\n",
        "                'subreddit': subreddit,\n",
        "                'title': post.title,\n",
        "                'text': post.selftext,\n",
        "                'id': post.id\n",
        "            }\n",
        "            all_posts.append(post_dict)\n",
        "\n",
        "            # Scrape comments\n",
        "            post.comments.replace_more(limit=0)\n",
        "            for comment in post.comments.list():\n",
        "              if search_term.lower() in comment.body.lower():\n",
        "                all_posts.append({\n",
        "                    'subreddit': subreddit,\n",
        "                    'title': f\"Comment on: {post.title}\",\n",
        "                    'text': comment.body,\n",
        "                    'id': comment.id\n",
        "                })\n",
        "            time.sleep(1.1) # Sleep for slightly over 1 second between requests\n",
        "    return pd.DataFrame(all_posts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSdgaZpWXZpx",
        "outputId": "ff8b133d-d0db-46a7-e441-8bbb8bb3ad45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of posts and comments mentioning 'clinical trial': 2925\n",
            "  subreddit                                              title text       id\n",
            "0    health  The federal government is putting up nearly $2...       1cp3eef\n",
            "1    health  Doc who claimed COVID shots cause magnetism ge...       1coqcs9\n",
            "2    health  A new COVID-19 variant FLiRT has emerged. Here...       1cp3zd0\n",
            "3    health  Just a few days on night shift has \"long-term\"...       1copscb\n",
            "4    health  Hallucinogen from Sonoran Desert toad venom sh...       1cov6mn\n"
          ]
        }
      ],
      "source": [
        "# Scrape data\n",
        "data = scrape_subreddits(subreddits)\n",
        "print(\"Number of posts and comments mentioning 'clinical trial':\", len(data))\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q2rYWpkvXli5"
      },
      "outputs": [],
      "source": [
        "# Save the data to a CSV file\n",
        "data.to_csv('reddit_scraped_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis"
      ],
      "metadata": {
        "id": "GYL2xRIi0RMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBB18reLPgA9",
        "outputId": "5f14231f-dd89-4095-ca09-5df274003e2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")\n",
        "emotion_pipeline = pipeline('text-classification', model='j-hartmann/emotion-english-distilroberta-base')"
      ],
      "metadata": {
        "id": "l45NsPGURTAf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CkWZQb8Kx7MM"
      },
      "outputs": [],
      "source": [
        "# Function to predict emotion using the pre-trained pipeline\n",
        "def predict_emotion(row):\n",
        "    if row['title'].startswith(\"Comment on:\"):\n",
        "        text_to_analyze = row['text']  # Use the text for comments\n",
        "    else:\n",
        "        text_to_analyze = row['title']  # Use the title otherwise\n",
        "\n",
        "    text_to_analyze = str(text_to_analyze).strip()\n",
        "\n",
        "    if not text_to_analyze:  # Check if the text is empty\n",
        "        return (\"Empty\", 0.0)\n",
        "\n",
        "    words = text_to_analyze.split()\n",
        "    truncated_text = \" \".join(words[:min(len(words), 514)])\n",
        "\n",
        "    try:\n",
        "        results = emotion_pipeline(truncated_text)\n",
        "        return results[0]['label'], results[0]['score']\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return (\"Error\", 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('reddit_scraped_data.csv')\n",
        "\n",
        "# Apply the emotion analysis function\n",
        "data['emotion'], data['confidence'] = zip(*data.apply(predict_emotion, axis=1))\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(data.head())\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "data.to_csv('emotion_analyzed_data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZdIRb6PWZHM",
        "outputId": "0d2d3c0f-7a52-4b2d-f488-72c7ced7ec0d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing text: The expanded size of the tensor (610) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 610].  Tensor sizes: [1, 514]\n",
            "  subreddit                                              title text       id  \\\n",
            "0    health  The federal government is putting up nearly $2...  NaN  1cp3eef   \n",
            "1    health  Doc who claimed COVID shots cause magnetism ge...  NaN  1coqcs9   \n",
            "2    health  A new COVID-19 variant FLiRT has emerged. Here...  NaN  1cp3zd0   \n",
            "3    health  Just a few days on night shift has \"long-term\"...  NaN  1copscb   \n",
            "4    health  Hallucinogen from Sonoran Desert toad venom sh...  NaN  1cov6mn   \n",
            "\n",
            "   emotion  confidence  \n",
            "0  neutral    0.938209  \n",
            "1  neutral    0.668158  \n",
            "2  neutral    0.839129  \n",
            "3  neutral    0.954349  \n",
            "4  neutral    0.477056  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['emotion'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K39En8JP0fM5",
        "outputId": "a6d277d9-81e3-412a-b769-cce4b2ad3c52"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "emotion\n",
              "neutral     1724\n",
              "sadness      361\n",
              "fear         269\n",
              "surprise     182\n",
              "disgust      173\n",
              "anger        115\n",
              "joy          100\n",
              "Error          1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}